{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf05eb06-c2e3-4498-ae54-5ad303b397b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24841e9-3062-4ca1-9262-b3a500b6e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "Scraping page 22...\n",
      "Scraping page 23...\n",
      "Scraping page 24...\n",
      "Scraping page 25...\n",
      "Scraping page 26...\n",
      "Scraping page 27...\n",
      "Scraping page 28...\n",
      "Scraping page 29...\n",
      "Scraping page 30...\n",
      "Scraping page 31...\n",
      "Scraping page 32...\n",
      "Scraping page 33...\n",
      "Scraping page 34...\n",
      "Scraping page 35...\n",
      "Scraping page 36...\n",
      "Scraping page 37...\n",
      "Scraping page 38...\n",
      "Scraping page 39...\n",
      "Scraping page 40...\n",
      "Scraping page 41...\n",
      "Scraping page 42...\n",
      "Scraping page 43...\n",
      "Scraping page 44...\n",
      "Scraping page 45...\n",
      "Scraping page 46...\n",
      "Scraping page 47...\n",
      "Scraping page 48...\n",
      "Scraping page 49...\n",
      "Scraping page 50...\n",
      "Scraping page 51...\n",
      "Scraping page 52...\n",
      "Scraping page 53...\n",
      "Scraping page 54...\n",
      "Scraping page 55...\n",
      "Scraping page 56...\n",
      "Scraping page 57...\n",
      "Scraping page 58...\n",
      "Scraping page 59...\n",
      "Scraping page 60...\n",
      "Scraping page 61...\n",
      "Scraping page 62...\n",
      "Scraping page 63...\n",
      "Scraping complete! Total products scraped: 1500\n",
      "                                        Product Name    Price Rating Discount  \\\n",
      "0           vivo T3 Lite 5G (Majestic Black, 128 GB)  ₹10,499    4.4  27% off   \n",
      "1           Motorola g45 5G (Brilliant Blue, 128 GB)  ₹12,999    4.4  13% off   \n",
      "2  POCO C61  - Locked with Airtel Prepaid (Diamon...   ₹5,399    4.1  40% off   \n",
      "3          Motorola g45 5G (Brilliant Green, 128 GB)  ₹10,999    4.3  15% off   \n",
      "4           Motorola g45 5G (Brilliant Blue, 128 GB)  ₹10,999    4.3  15% off   \n",
      "\n",
      "          Reviews                                       Storage  \\\n",
      "0  52,124 Ratings  4 GB RAM | 128 GB ROM | Expandable Upto 1 TB   \n",
      "1  95,203 Ratings  8 GB RAM | 128 GB ROM | Expandable Upto 1 TB   \n",
      "2  72,282 Ratings   4 GB RAM | 64 GB ROM | Expandable Upto 1 TB   \n",
      "3  25,202 Ratings  4 GB RAM | 128 GB ROM | Expandable Upto 1 TB   \n",
      "4  25,202 Ratings  4 GB RAM | 128 GB ROM | Expandable Upto 1 TB   \n",
      "\n",
      "                          Processor                              Camera  \\\n",
      "0      16.66 cm (6.56 inch) Display       50MP + 2MP | 8MP Front Camera   \n",
      "1   16.51 cm (6.5 inch) HD+ Display      50MP + 2MP | 16MP Front Camera   \n",
      "2  17.04 cm (6.71 inch) HD+ Display  8MP Rear Camera | 5MP Front Camera   \n",
      "3   16.51 cm (6.5 inch) HD+ Display      50MP + 2MP | 16MP Front Camera   \n",
      "4   16.51 cm (6.5 inch) HD+ Display      50MP + 2MP | 16MP Front Camera   \n",
      "\n",
      "            Battery                        Display  \n",
      "0  5000 mAh Battery       Dimensity 6300 Processor  \n",
      "1  5000 mAh Battery  Snapdragon 6s Gen 3 Processor  \n",
      "2  5000 mAh Battery            Helio G36 Processor  \n",
      "3  5000 mAh Battery  Snapdragon 6s Gen 3 Processor  \n",
      "4  5000 mAh Battery  Snapdragon 6s Gen 3 Processor  \n"
     ]
    }
   ],
   "source": [
    "# Define headers to mimic a real browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Base Flipkart search URL \n",
    "base_url = \"https://www.flipkart.com/search?q=mobiles&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "# Define number of pages to scrape\n",
    "max_pages = 150  # Increase pages to ensure 800+ rows\n",
    "data = []  # List to store product data\n",
    "\n",
    "for page in range(1, max_pages + 1):\n",
    "    print(f\"Scraping page {page}...\")\n",
    "\n",
    "    # Construct the URL for the current page\n",
    "    search_url = base_url + str(page)\n",
    "    \n",
    "    # Send GET request\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find product containers\n",
    "        products = soup.find_all(\"div\", class_=\"tUxRFH\")\n",
    "\n",
    "        # Extract product details\n",
    "        for product in products:\n",
    "            try:\n",
    "                name = product.find(\"div\", class_=\"KzDlHZ\").text.strip() if product.find(\"div\", class_=\"KzDlHZ\") else \"No Name\"\n",
    "                price = product.find(\"div\", class_=\"Nx9bqj _4b5DiR\").text.strip() if product.find(\"div\", class_=\"Nx9bqj _4b5DiR\") else \"No Price\"\n",
    "                rating = product.find(\"div\", class_=\"XQDdHH\").text.strip() if product.find(\"div\", class_=\"XQDdHH\") else \"No Rating\"\n",
    "                \n",
    "                # Extract additional details\n",
    "                discount = product.find(\"div\", class_=\"UkUFwK\").text.strip() if product.find(\"div\", class_=\"UkUFwK\") else \"No Discount\"\n",
    "                reviews = product.find(\"span\", class_=\"Wphh3N\").text.split(\"&\")[0].strip() if product.find(\"span\", class_=\"Wphh3N\") else \"No Reviews\"\n",
    "                features = product.find_all(\"ul\", class_=\"G4BRas\")  # Feature container\n",
    "                \n",
    "                if features:\n",
    "                    specs = features[0].find_all(\"li\")  # List of specs inside the container\n",
    "                    \n",
    "                    storage = specs[0].text.strip() if len(specs) > 0 else \"No Info\"\n",
    "                    processor = specs[1].text.strip() if len(specs) > 1 else \"No Info\"\n",
    "                    camera = specs[2].text.strip() if len(specs) > 2 else \"No Info\"\n",
    "                    battery = specs[3].text.strip() if len(specs) > 3 else \"No Info\"\n",
    "                    display = specs[4].text.strip() if len(specs) > 4 else \"No Info\"\n",
    "                else:\n",
    "                    storage, processor, camera, battery, display = \"No Info\", \"No Info\", \"No Info\", \"No Info\", \"No Info\"\n",
    "\n",
    "                # Append data to list\n",
    "                data.append([name, price, rating, discount, reviews, storage, processor, camera, battery, display])\n",
    "                \n",
    "                # Stop once we reach 1500+ rows\n",
    "                if len(data) >= 1500:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                pass  # Skip if data is missing\n",
    "        \n",
    "        # Stop scraping if we have enough rows\n",
    "        if len(data) >= 1500:\n",
    "            break\n",
    "\n",
    "        # Delay to avoid getting blocked\n",
    "        time.sleep(2)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch page {page}. Status code: {response.status_code}\")\n",
    "        break  # Stop if request fails\n",
    "\n",
    "# Create DataFrame with 14+ columns\n",
    "df = pd.DataFrame(data, columns=[\"Product Name\", \"Price\", \"Rating\", \"Discount\", \"Reviews\", \"Storage\", \"Processor\", \"Camera\", \"Battery\", \"Display\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"flipkart_products_1501.csv\", index=False)\n",
    "\n",
    "print(f\"Scraping complete! Total products scraped: {len(df)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522748cb-320d-407d-a163-8988a96261f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
